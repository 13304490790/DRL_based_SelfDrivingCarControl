{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRL Based Self Driving Car Control (Image + Sensor)\n",
    "\n",
    "## Distributional Reinforcement Learning with Quantile Regression\n",
    "\n",
    "This notebook is DRL code for the project 'DRL based Self Driving Car Control' <br>\n",
    "This version uses both **Image data from camera** and **Sensor data from LIDAR** as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment path\n",
    "\n",
    "Be sure to set `env_name` to the name of the Unity environment file you want to launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"../environment/windows_penalty.exe\" # Name of the Unity environment to launch\n",
    "train_mode = True # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data (LIDAR): \n",
      "[  1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.9755246    0.91600198   0.86357307   0.81705666   0.77551937\n",
      "   0.73821479   0.70453942   0.67399871   0.64618438   0.62075633\n",
      "   0.59742886   0.57596022   0.5561446    0.53780544   0.52079082\n",
      "   0.50496876   0.49022466   0.47645816   0.46358114   0.45151567\n",
      "   0.44019303   0.42955208   0.41953811   0.41010255   0.40120158\n",
      "   0.39279586   0.38485005   0.37733197   0.37021253   0.36346549\n",
      "   0.35706681   0.35099453   0.34522879   0.33975118   0.33454502\n",
      "   0.32959491   0.32488668   0.32040724   0.31614468   0.31208783\n",
      "   0.30822647   0.30455115   0.30105308   0.29772413   0.29455668\n",
      "   0.29154381   0.288679     0.28595623   0.28336981   0.2809146\n",
      "   0.27858567   0.27637851   0.27428898   0.27231315   0.27044734\n",
      "   0.26868826   0.26703268   0.26547778   0.26402083   0.26265934\n",
      "   0.26139107   0.26021382   0.25912577   0.25812501   0.25721005\n",
      "   0.25637937   0.25563163   0.25496569   0.25438049   0.25387514\n",
      "   0.25344881   0.25310093   0.25283089   0.25263828   0.25252286\n",
      "   0.25248438   0.25252286   0.25263828   0.25283089   0.25310093\n",
      "   0.25344881   0.25387514   0.25438049   0.25496572   0.25563163\n",
      "   0.25637937   0.25721005   0.25812504   0.25912577   0.26021382\n",
      "   0.2613911    0.26265937   0.26402086   0.26547781   0.26703271\n",
      "   0.26868829   0.27044743   0.27231318   0.27428904   0.27637854\n",
      "   0.27858567   0.28091457   0.28336984   0.2859562    0.28867906\n",
      "   0.29154381   0.29455668   0.29772413   0.30105308   0.30455118\n",
      "   0.3082265    0.3120878    0.31614468   0.32040721   0.32488671\n",
      "   0.32959491   0.33454508   0.33975121   0.34522879   0.35099462\n",
      "   0.35706681   0.36346555   0.37021261   0.37733203   0.38485011\n",
      "   0.39279595   0.40120178   0.41010267   0.4195382    0.42955217\n",
      "   0.44019303   0.45151576   0.46358114   0.47645825   0.49022475\n",
      "   0.50496876   0.52079082   0.53780544   0.8056162    0.79863602\n",
      "   0.79201484   0.78574008   0.77979958   0.7741822    0.7688778\n",
      "   0.76387662   0.75916994   0.7547493    0.75060725   0.74673665\n",
      "   0.7431308    0.739784     0.73669058   0.73384559   0.73124427\n",
      "   0.72888267   0.72675687   0.72486359   0.7231999    0.72176319\n",
      "   0.72055119   0.71956211   0.71879435   0.71824682   0.71791863\n",
      "   0.71780932   1.           0.73828739   0.73885024   0.7396394\n",
      "   0.74065602   0.74190187   0.74337864   0.74508876   0.74703485\n",
      "   0.72526538   0.72761542   0.73020375   0.73303467   0.73611271\n",
      "   0.73944294   0.74303085   0.74688226   0.7510038    0.75540245\n",
      "   0.76008582   0.76506215   0.77034026   0.77592981   0.78184074\n",
      "   0.78808439   0.79467267   0.80161822   0.80893487   0.52898562\n",
      "   0.51291454   0.49793857   0.48395553   0.47087574   0.45862055\n",
      "   0.44711965   0.4363113    0.42613983   0.41655573   0.40751475\n",
      "   0.399611     0.38823813   0.3806538    0.3734718    0.3666653\n",
      "   0.36021024   0.35408458   0.34826803   0.34274226   0.33749029\n",
      "   0.33249652   0.32774684   0.32322803   0.31892782   0.31483531\n",
      "   0.31093997   0.30723232   0.30370349   0.30034512   0.29714981\n",
      "   0.29411048   0.29122046   0.2884737    0.28881615   0.29910675\n",
      "   0.31025571   0.32237002   0.33557519   0.35001999   0.36588031\n",
      "   0.38336843   0.40274113   0.42431211   0.44846955   0.24207902\n",
      "   0.24091013   0.2398251    0.2388223    0.25435534   0.71093136\n",
      "   0.70863533   0.7065686    0.70472795   0.70311046   0.70171368\n",
      "   0.70053536   0.69957376   0.69882733   0.698295     0.69797587\n",
      "   0.6978696    1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.46766621   0.39589906   0.38227844   0.36967266   0.35797733\n",
      "   0.34710175   0.33696681   0.32750422   0.3186529    0.31535536\n",
      "   0.31916118   0.32315952   0.32736021   0.33177397   0.33641231\n",
      "   0.34128767   0.34641343   0.35180423   0.35747606   0.36344635\n",
      "   0.36973414   0.37635988   0.3833462    0.39071813   0.39850292\n",
      "   0.40673083   0.418935     0.41482678   0.42437106   0.43450052\n",
      "   0.44526401   0.45671701   0.46892133   0.48194665   0.49587208\n",
      "   0.51078594   0.59662944   0.57361192   0.57813853   0.58058214\n",
      "   0.57576889   0.57120734   0.58600146   0.61122501   0.63892192\n",
      "   0.66946077   0.78772271   0.8299135    0.89621913   0.95063126\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.           0.           0.           1.           0.\n",
      "   0.60000002   0.           0.           0.           0.\n",
      "   0.           0.         -10.        ]\n",
      "Image data (Front Camera): \n",
      "{}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "# Examine the state space for the default brain\n",
    "print(\"Sensor data (LIDAR): \\n{}\".format(env_info.vector_observations[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "Num_obs = len(env_info.visual_observations)\n",
    "\n",
    "print(\"Image data (Front Camera): \\n{}\")\n",
    "if Num_obs > 1:\n",
    "    f, axarr = plt.subplots(1, Num_obs, figsize=(20,10))\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr[i].imshow(observation[0,:,:,:])\n",
    "            axarr[i].axis('off')\n",
    "        else:\n",
    "            axarr[i].imshow(observation[0,:,:,0])\n",
    "            axarr[i].axis('off')\n",
    "else:\n",
    "    f, axarr = plt.subplots(1, Num_obs)\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr.imshow(observation[0,:,:,:])\n",
    "            axarr.axis('off')\n",
    "        else:\n",
    "            axarr.imshow(observation[0,:,:,0])\n",
    "            axarr.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithm = 'QR-DQN'\n",
    "Num_action = brain.vector_action_space_size\n",
    "\n",
    "# QR-DQN Parameter\n",
    "Num_quantile = 50\n",
    "        \n",
    "# parameter for DQN\n",
    "Num_replay_memory = 100000\n",
    "Num_start_training = 50000\n",
    "Num_training = 1000000\n",
    "Num_update = 10000\n",
    "Num_batch = 32\n",
    "Num_test = 100000\n",
    "Num_skipFrame = 4\n",
    "Num_stackFrame = 4\n",
    "Num_colorChannel = 1\n",
    "\n",
    "Epsilon = 1.0\n",
    "Final_epsilon = 0.1\n",
    "Gamma = 0.99\n",
    "Learning_rate = 0.00005\n",
    "\n",
    "# Parameter for LSTM\n",
    "Num_dataSize = 366\n",
    "Num_cellState = 512\n",
    "\n",
    "# Parameters for network\n",
    "img_size = 80\n",
    "sensor_size = 360\n",
    "\n",
    "first_conv   = [8,8,Num_colorChannel * Num_stackFrame * Num_obs,32]\n",
    "second_conv  = [4,4,32,64]\n",
    "third_conv   = [3,3,64,64]\n",
    "first_dense  = [10*10*64 + Num_cellState, 512]\n",
    "second_dense = [first_dense[1], Num_action * Num_quantile]\n",
    "\n",
    "# Path of the network model\n",
    "load_path = '../saved_networks/2018-09-10_11_20_QR-DQN_both/model.ckpt'\n",
    "\n",
    "# Parameters for session\n",
    "Num_plot_episode = 5\n",
    "Num_step_save = 50000\n",
    "\n",
    "GPU_fraction = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "\treturn tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "# Xavier Weights initializer\n",
    "def xavier_initializer(shape):\n",
    "\tdim_sum = np.sum(shape)\n",
    "\tif len(shape) == 1:\n",
    "\t\tdim_sum += 1\n",
    "\tbound = np.sqrt(2.0 / dim_sum)\n",
    "\treturn tf.random_uniform(shape, minval=-bound, maxval=bound)\n",
    "\n",
    "# Convolution function\n",
    "def conv2d(x,w, stride):\n",
    "\treturn tf.nn.conv2d(x,w,strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "# Assign network variables to target network\n",
    "def assign_network_to_target():\n",
    "\t# Get trainable variables\n",
    "\ttrainable_variables = tf.trainable_variables()\n",
    "\t# network lstm variables\n",
    "\ttrainable_variables_network = [var for var in trainable_variables if var.name.startswith('network')]\n",
    "\n",
    "\t# target lstm variables\n",
    "\ttrainable_variables_target = [var for var in trainable_variables if var.name.startswith('target')]\n",
    "\n",
    "    # assign network variables to target network\n",
    "\tfor i in range(len(trainable_variables_network)):\n",
    "\t\tsess.run(tf.assign(trainable_variables_target[i], trainable_variables_network[i]))\n",
    "\n",
    "# Code for tensorboard\n",
    "def setup_summary():\n",
    "    episode_speed      = tf.Variable(0.)\n",
    "    episode_overtake   = tf.Variable(0.)\n",
    "    episode_lanechange = tf.Variable(0.)\n",
    "\n",
    "    tf.summary.scalar('Average_Speed/' + str(Num_plot_episode) + 'episodes', episode_speed)\n",
    "    tf.summary.scalar('Average_overtake/' + str(Num_plot_episode) + 'episodes', episode_overtake)\n",
    "    tf.summary.scalar('Average_lanechange/' + str(Num_plot_episode) + 'episodes', episode_lanechange)\n",
    "\n",
    "    summary_vars = [episode_speed, episode_overtake, episode_lanechange]\n",
    "    summary_placeholders = [tf.placeholder(tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in range(len(summary_vars))]\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return summary_placeholders, update_ops, summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Input\n",
    "x_image = tf.placeholder(tf.float32, shape = [None, img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs])\n",
    "x_normalize = (x_image - (255.0/2)) / (255.0/2)\n",
    "\n",
    "x_sensor = tf.placeholder(tf.float32, shape = [None, Num_stackFrame, Num_dataSize])\n",
    "x_unstack = tf.unstack(x_sensor, axis = 1)\n",
    "\n",
    "with tf.variable_scope('network'):\n",
    "    # Convolution variables\n",
    "    w_conv1 = weight_variable(first_conv)\n",
    "    b_conv1 = bias_variable([first_conv[3]])\n",
    "\n",
    "    w_conv2 = weight_variable(second_conv)\n",
    "    b_conv2 = bias_variable([second_conv[3]])\n",
    "\n",
    "    w_conv3 = weight_variable(third_conv)\n",
    "    b_conv3 = bias_variable([third_conv[3]])\n",
    "\n",
    "    # Densely connect layer variables\n",
    "    w_fc1 = weight_variable(first_dense)\n",
    "    b_fc1 = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2 = weight_variable(second_dense)\n",
    "    b_fc2 = bias_variable([second_dense[1]])\n",
    "    \n",
    "    # LSTM cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out, rnn_state = tf.nn.static_rnn(inputs = x_unstack, cell = cell, dtype = tf.float32)\n",
    "    \n",
    "# Network\n",
    "h_conv1 = tf.nn.relu(conv2d(x_normalize, w_conv1, 4) + b_conv1)\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, w_conv2, 2) + b_conv2)\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, w_conv3, 1) + b_conv3)\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_conv3, [-1, 10 * 10 * 64])\n",
    "rnn_out = rnn_out[-1]\n",
    "h_concat = tf.concat([h_pool3_flat, rnn_out], axis = 1)\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_concat, w_fc1)+b_fc1)\n",
    "\n",
    "# Get Q value for each action\n",
    "logits = tf.matmul(h_fc1, w_fc2) + b_fc2\n",
    "logits_reshape = tf.reshape(logits, [-1, Num_action, Num_quantile])\n",
    "Q_action = tf.reduce_sum(tf.multiply(1/Num_quantile, logits_reshape), axis = 2)\n",
    "\n",
    "with tf.variable_scope('target'):\n",
    "    # Convolution variables target\n",
    "    w_conv1_target = weight_variable(first_conv)\n",
    "    b_conv1_target = bias_variable([first_conv[3]])\n",
    "\n",
    "    w_conv2_target = weight_variable(second_conv)\n",
    "    b_conv2_target = bias_variable([second_conv[3]])\n",
    "\n",
    "    w_conv3_target = weight_variable(third_conv)\n",
    "    b_conv3_target = bias_variable([third_conv[3]])\n",
    "\n",
    "    # Densely connect layer variables target\n",
    "    w_fc1_target = weight_variable(first_dense)\n",
    "    b_fc1_target = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2_target = weight_variable(second_dense)\n",
    "    b_fc2_target = bias_variable([second_dense[1]])\n",
    "\n",
    "    # LSTM cell\n",
    "    cell_target = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out_target, rnn_state_target = tf.nn.static_rnn(inputs = x_unstack, cell = cell_target, dtype = tf.float32)\n",
    "    \n",
    "# Target Network\n",
    "h_conv1_target = tf.nn.relu(conv2d(x_normalize, w_conv1_target, 4) + b_conv1_target)\n",
    "h_conv2_target = tf.nn.relu(conv2d(h_conv1_target, w_conv2_target, 2) + b_conv2_target)\n",
    "h_conv3_target = tf.nn.relu(conv2d(h_conv2_target, w_conv3_target, 1) + b_conv3_target)\n",
    "\n",
    "h_pool3_flat_target = tf.reshape(h_conv3_target, [-1, 10 * 10 * 64])\n",
    "rnn_out_target = rnn_out_target[-1]\n",
    "h_concat_target = tf.concat([h_pool3_flat_target, rnn_out_target], axis = 1)\n",
    "\n",
    "h_fc1_target  = tf.nn.relu(tf.matmul(h_concat_target, w_fc1_target)+b_fc1_target)\n",
    "\n",
    "# Get Q value for each action\n",
    "logits_target = tf.matmul(h_fc1, w_fc2_target) + b_fc2_target\n",
    "logits_reshape_target = tf.reshape(logits_target, [-1, Num_action, Num_quantile])\n",
    "Q_action_target = tf.reduce_sum(tf.multiply(1/Num_quantile, logits_reshape_target), axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Train\n",
    "theta_loss = tf.placeholder(tf.float32, shape = [None, Num_quantile])\n",
    "action_binary_loss = tf.placeholder(tf.float32, shape = [None, Num_action, Num_quantile])\n",
    "\n",
    "# Get valid logits \n",
    "logit_valid = tf.multiply(logits_reshape, action_binary_loss)\n",
    "logit_valid_nonzero = tf.reduce_sum(logit_valid, axis = 1)\n",
    "\n",
    "# Stack i and j\n",
    "theta_loss_tile = tf.tile(tf.expand_dims(theta_loss, axis=2), [1, 1, Num_quantile])\n",
    "logit_valid_tile = tf.tile(tf.expand_dims(logit_valid_nonzero, axis=1), [1, Num_quantile, 1])\n",
    "\n",
    "error_loss = theta_loss_tile - logit_valid_tile\n",
    "\n",
    "# Get Huber loss\n",
    "Huber_loss = tf.losses.huber_loss(theta_loss_tile, logit_valid_tile, reduction = tf.losses.Reduction.NONE)\n",
    "\n",
    "# Get tau\n",
    "min_tau = 1/(2*Num_quantile)\n",
    "max_tau = (2*(Num_quantile-1)+3)/(2*Num_quantile)\n",
    "tau = tf.reshape (tf.range(min_tau, max_tau, 1/Num_quantile), [1, Num_quantile])\n",
    "inv_tau = 1.0 - tau \n",
    "\n",
    "# Get Loss\n",
    "Loss = tf.where(tf.less(error_loss, 0.0), inv_tau * Huber_loss, tau * Huber_loss)\n",
    "Loss = tf.reduce_mean(tf.reduce_sum(tf.reduce_mean(Loss, axis = 2), axis = 1))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = Learning_rate, epsilon = 1e-02/Num_batch).minimize(Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = GPU_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training or Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference? / Training?(1=Inference/2=Training): 2\n"
     ]
    }
   ],
   "source": [
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# check_save = 1\n",
    "check_save = input('Inference? / Training?(1=Inference/2=Training): ')\n",
    "\n",
    "if check_save == '1':\n",
    "    # Directly start inference\n",
    "    Num_start_training = 0\n",
    "    Num_training = 0\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, load_path)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "# date - hour - minute of training time\n",
    "date_time = str(datetime.date.today()) + '_' + str(datetime.datetime.now().hour) + '_' + str(datetime.datetime.now().minute)\n",
    "\n",
    "# Make folder for save data\n",
    "os.makedirs('../saved_networks/' + date_time + '_' + algorithm + '_both')\n",
    "\n",
    "# Summary for tensorboard\n",
    "summary_placeholders, update_ops, summary_op = setup_summary()\n",
    "summary_writer = tf.summary.FileWriter('../saved_networks/' + date_time + '_' + algorithm + '_both', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize input \n",
    "def input_initialization(env_info):\n",
    "    # Observation\n",
    "    observation_stack_obs = np.zeros([img_size, img_size, Num_colorChannel * Num_obs])\n",
    "    \n",
    "    for i in range(Num_obs):\n",
    "        observation = 255 * env_info.visual_observations[i]\n",
    "        observation = np.uint8(observation)\n",
    "        observation = np.reshape(observation, (observation.shape[1], observation.shape[2], 3))\n",
    "        observation = cv2.resize(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 1:\n",
    "            observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "            observation = np.reshape(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 3:\n",
    "            observation_stack_obs[:,:, Num_colorChannel * i: Num_colorChannel * (i+1)] = observation\n",
    "        else:\n",
    "            observation_stack_obs[:,:, i] = observation\n",
    "\n",
    "    observation_set = []\n",
    "\n",
    "    # State\n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "    state_set = []\n",
    "        \n",
    "    for i in range(Num_skipFrame * Num_stackFrame):\n",
    "        observation_set.append(observation_stack_obs)\n",
    "        state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    observation_stack = np.zeros((img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs))\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "    \n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        observation_stack[:,:,Num_obs * stack_frame: Num_obs * (stack_frame+1)] = observation_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "    \n",
    "    observation_stack = np.uint8(observation_stack)\n",
    "    state_stack = np.uint8(state_stack)\n",
    "    \n",
    "    return observation_stack, observation_set, state_stack, state_set\n",
    "\n",
    "# Resize input information \n",
    "def resize_input(env_info, observation_set, state_set):\n",
    "    # Stack observation according to the number of observations\n",
    "    observation_stack_obs = np.zeros([img_size, img_size, Num_colorChannel * Num_obs])\n",
    "\n",
    "    for i in range(Num_obs):\n",
    "        observation = 255 * env_info.visual_observations[i]\n",
    "        observation = np.uint8(observation)\n",
    "        observation = np.reshape(observation, (observation.shape[1], observation.shape[2], 3))\n",
    "        observation = cv2.resize(observation, (img_size, img_size))\n",
    "        \n",
    "        if Num_colorChannel == 1:\n",
    "            observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "            observation = np.reshape(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 3:\n",
    "            observation_stack_obs[:,:, Num_colorChannel * i: Num_colorChannel * (i+1)] = observation\n",
    "        else:\n",
    "            observation_stack_obs[:,:,i] = observation\n",
    "    \n",
    "    # Add observations to the observation_set\n",
    "    observation_set.append(observation_stack_obs)\n",
    "    \n",
    "    # State \n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "\n",
    "    # Add state to the state_set\n",
    "    state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    observation_stack = np.zeros((img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs))\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "\n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        observation_stack[:,:,Num_obs * stack_frame: Num_obs * (stack_frame+1)] = observation_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "\n",
    "    del observation_set[0]\n",
    "    del state_set[0]\n",
    "    \n",
    "    observation_stack = np.uint8(observation_stack)\n",
    "    state_stack = np.uint8(state_stack)\n",
    "        \n",
    "    return observation_stack, observation_set, state_stack, state_set\n",
    "\n",
    "# Get progress according to the number of steps\n",
    "def get_progress(step, Epsilon):\n",
    "    if step <= Num_start_training:\n",
    "        # Observation\n",
    "        progress = 'Observing'\n",
    "        train_mode = True\n",
    "        Epsilon = 1\n",
    "    elif step <= Num_start_training + Num_training:\n",
    "        # Training\n",
    "        progress = 'Training'\n",
    "        train_mode = True\n",
    "        \n",
    "        # Decrease the epsilon value\n",
    "        if Epsilon > Final_epsilon:\n",
    "            Epsilon -= 1.0/Num_training\n",
    "    elif step < Num_start_training + Num_training + Num_test:\n",
    "        # Testing\n",
    "        progress = 'Testing'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "    else:\n",
    "        # Finished\n",
    "        progress = 'Finished'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "        \n",
    "    return progress, train_mode, Epsilon \n",
    "\n",
    "# Select action according to the progress of training\n",
    "def select_action(progress, sess, observation_stack, state_stack, Epsilon):\n",
    "    if progress == \"Observing\":\n",
    "        # Random action \n",
    "        Q_value = 0\n",
    "        action = np.zeros([Num_action])\n",
    "        action[random.randint(0, Num_action - 1)] = 1.0\n",
    "    elif progress == \"Training\":\n",
    "        # if random value(0-1) is smaller than Epsilon, action is random. \n",
    "        # Otherwise, action is the one which has the max Q value\n",
    "        if random.random() < Epsilon:\n",
    "            Q_value = 0\n",
    "            action = np.zeros([Num_action])\n",
    "            action[random.randint(0, Num_action - 1)] = 1\n",
    "        else:\n",
    "            Q_value = Q_action.eval(feed_dict={x_image: [observation_stack], x_sensor: [state_stack]})\n",
    "            action = np.zeros([Num_action])\n",
    "            action[np.argmax(Q_value)] = 1\n",
    "    else:\n",
    "        # Max Q action \n",
    "        Q_value = Q_action.eval(feed_dict={x_image: [observation_stack], x_sensor: [state_stack]})\n",
    "        action = np.zeros([Num_action])\n",
    "        action[np.argmax(Q_value)] = 1\n",
    "        \n",
    "    return action, Q_value\n",
    "\n",
    "def train(Replay_memory, sess, step):\n",
    "    # Select minibatch\n",
    "    minibatch =  random.sample(Replay_memory, Num_batch)\n",
    "\n",
    "    # Save the each batch data\n",
    "    observation_batch      = [batch[0] for batch in minibatch]\n",
    "    state_batch            = [batch[1] for batch in minibatch]\n",
    "    action_batch           = [batch[2] for batch in minibatch]\n",
    "    reward_batch           = [batch[3] for batch in minibatch]\n",
    "    observation_next_batch = [batch[4] for batch in minibatch]\n",
    "    state_next_batch       = [batch[5] for batch in minibatch]\n",
    "    terminal_batch \t       = [batch[6] for batch in minibatch]\n",
    "\n",
    "    # Update target network according to the Num_update value\n",
    "    if step % Num_update == 0:\n",
    "        assign_network_to_target()\n",
    "    \n",
    "    \n",
    "    # Get Target\n",
    "    Q_batch = Q_action.eval(feed_dict = {x_image: observation_next_batch, x_sensor: state_next_batch})\n",
    "    theta_batch = logits_reshape_target.eval(feed_dict = {x_image: observation_next_batch, x_sensor: state_next_batch})\n",
    "\n",
    "    theta_target = []\n",
    "\n",
    "    for i in range(len(minibatch)):\n",
    "        theta_target.append([])\n",
    "        for j in range(Num_quantile):\n",
    "            if terminal_batch[i] == True:\n",
    "                theta_target[i].append(reward_batch[i])\n",
    "            else:\n",
    "                theta_target[i].append(reward_batch[i] + Gamma * theta_batch[i, np.argmax(Q_batch[i]), j])\n",
    "\n",
    "    # Calculate action binary\n",
    "    action_binary = np.zeros([Num_batch, Num_action, Num_quantile])\n",
    "\n",
    "    for i in range(len(action_batch)):\n",
    "        action_batch_max = np.argmax(action_batch[i])\n",
    "        action_binary[i, action_batch_max, :] = 1\n",
    "\n",
    "    _, loss = sess.run([train_step, Loss],feed_dict = {x_image: observation_batch,\n",
    "                                                       x_sensor: state_batch,\n",
    "                                                       theta_loss: theta_target, \n",
    "                                                       action_binary_loss: action_binary})\n",
    "\n",
    "# Experience Replay \n",
    "def Experience_Replay(progress, Replay_memory, obs_stack, s_stack, action, reward, next_obs_stack, next_s_stack, terminal):\n",
    "    if progress != 'Testing':\n",
    "        # If length of replay memeory is more than the setting value then remove the first one\n",
    "        if len(Replay_memory) > Num_replay_memory:\n",
    "            del Replay_memory[0]\n",
    "\n",
    "        # Save experience to the Replay memory\n",
    "        Replay_memory.append([obs_stack, s_stack, action, reward, next_obs_stack, next_s_stack, terminal])\n",
    "    else:\n",
    "        # Empty the replay memory if testing\n",
    "        Replay_memory = []\n",
    "    \n",
    "    return Replay_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "Replay_memory = []\n",
    "\n",
    "step = 1\n",
    "score = 0\n",
    "score_board = 0\n",
    "\n",
    "episode = 0\n",
    "step_per_episode = 0\n",
    "\n",
    "speed_list = []\n",
    "overtake_list = []\n",
    "lanechange_list = []\n",
    "\n",
    "train_mode = True\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "observation_stack, observation_set, state_stack, state_set = input_initialization(env_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4716 / episode: 0 / progress: Observing / epsilon: 1 / score: 928.8607370555401\n",
      "step: 9120 / episode: 0 / progress: Observing / epsilon: 1 / score: 1090.010880857706\n",
      "step: 14112 / episode: 0 / progress: Observing / epsilon: 1 / score: 215.05138912796974\n",
      "step: 18900 / episode: 0 / progress: Observing / epsilon: 1 / score: 708.7745587974787\n",
      "step: 23388 / episode: 0 / progress: Observing / epsilon: 1 / score: 1119.4620645940304\n",
      "step: 27952 / episode: 0 / progress: Observing / epsilon: 1 / score: 785.8793004900217\n",
      "step: 32573 / episode: 0 / progress: Observing / epsilon: 1 / score: 662.7685752213001\n",
      "step: 34907 / episode: 0 / progress: Observing / epsilon: 1 / score: 413.81883031129837\n",
      "step: 37344 / episode: 0 / progress: Observing / epsilon: 1 / score: 563.0496207028627\n",
      "step: 42144 / episode: 0 / progress: Observing / epsilon: 1 / score: 570.8713311702013\n",
      "step: 46814 / episode: 0 / progress: Observing / epsilon: 1 / score: 966.4257670640945\n",
      "step: 51361 / episode: 0 / progress: Training / epsilon: 0.9986399999999609 / score: 686.6829201132059\n",
      "step: 55306 / episode: 1 / progress: Training / epsilon: 0.9946949999998475 / score: 903.6991984993219\n",
      "step: 60535 / episode: 2 / progress: Training / epsilon: 0.9894659999996971 / score: -501.70490646362305\n",
      "step: 61573 / episode: 3 / progress: Training / epsilon: 0.9884279999996672 / score: -33.521052822470665\n",
      "step: 66277 / episode: 4 / progress: Training / epsilon: 0.983723999999532 / score: 469.1722104549408\n",
      "step: 71129 / episode: 5 / progress: Training / epsilon: 0.9788719999993925 / score: 488.24090281128883\n",
      "step: 75654 / episode: 6 / progress: Training / epsilon: 0.9743469999992623 / score: 875.3208016902208\n",
      "step: 79856 / episode: 7 / progress: Training / epsilon: 0.9701449999991415 / score: 1389.7237932384014\n",
      "step: 84424 / episode: 8 / progress: Training / epsilon: 0.9655769999990101 / score: 885.439646795392\n",
      "step: 85339 / episode: 9 / progress: Training / epsilon: 0.9646619999989838 / score: 232.96182569861412\n",
      "step: 87639 / episode: 10 / progress: Training / epsilon: 0.9623619999989177 / score: 697.3982417285442\n",
      "step: 91929 / episode: 11 / progress: Training / epsilon: 0.9580719999987943 / score: 1360.2821611315012\n",
      "step: 92449 / episode: 12 / progress: Training / epsilon: 0.9575519999987794 / score: 327.0381070673466\n",
      "step: 95292 / episode: 13 / progress: Training / epsilon: 0.9547089999986976 / score: 431.3314965516329\n",
      "step: 100140 / episode: 14 / progress: Training / epsilon: 0.9498609999985582 / score: 69.24086113274097\n",
      "step: 104632 / episode: 15 / progress: Training / epsilon: 0.945368999998429 / score: 958.0952748954296\n",
      "step: 107868 / episode: 16 / progress: Training / epsilon: 0.942132999998336 / score: 933.5938173681498\n",
      "step: 109882 / episode: 17 / progress: Training / epsilon: 0.9401189999982781 / score: 2.1644163131713867\n",
      "step: 112458 / episode: 18 / progress: Training / epsilon: 0.937542999998204 / score: 474.0411103963852\n",
      "step: 113513 / episode: 19 / progress: Training / epsilon: 0.9364879999981737 / score: 310.65350449085236\n",
      "step: 117963 / episode: 20 / progress: Training / epsilon: 0.9320379999980457 / score: 1126.424753755331\n",
      "step: 119787 / episode: 21 / progress: Training / epsilon: 0.9302139999979933 / score: 299.43865740299225\n",
      "step: 121814 / episode: 22 / progress: Training / epsilon: 0.928186999997935 / score: -73.75555205345154\n",
      "step: 122242 / episode: 23 / progress: Training / epsilon: 0.9277589999979227 / score: 176.5749886929989\n",
      "step: 126727 / episode: 24 / progress: Training / epsilon: 0.9232739999977937 / score: 933.025203615427\n",
      "step: 131527 / episode: 25 / progress: Training / epsilon: 0.9184739999976557 / score: 349.9111801683903\n",
      "step: 132954 / episode: 26 / progress: Training / epsilon: 0.9170469999976146 / score: 435.4731907248497\n",
      "step: 133228 / episode: 27 / progress: Training / epsilon: 0.9167729999976068 / score: 156.42122848331928\n",
      "step: 136371 / episode: 28 / progress: Training / epsilon: 0.9136299999975164 / score: 854.4688003957272\n",
      "step: 137363 / episode: 29 / progress: Training / epsilon: 0.9126379999974878 / score: 442.0806643217802\n",
      "step: 137983 / episode: 30 / progress: Training / epsilon: 0.91201799999747 / score: 104.45560918748379\n",
      "step: 142386 / episode: 31 / progress: Training / epsilon: 0.9076149999973434 / score: 975.5645651370287\n",
      "step: 146725 / episode: 32 / progress: Training / epsilon: 0.9032759999972186 / score: 1077.4563696682453\n",
      "step: 151153 / episode: 33 / progress: Training / epsilon: 0.8988479999970913 / score: 1126.9194446057081\n",
      "step: 155519 / episode: 34 / progress: Training / epsilon: 0.8944819999969658 / score: 1331.423519745469\n",
      "step: 159882 / episode: 35 / progress: Training / epsilon: 0.8901189999968403 / score: 1026.2862891554832\n",
      "step: 164083 / episode: 36 / progress: Training / epsilon: 0.8859179999967195 / score: 852.9594088345766\n",
      "step: 165547 / episode: 37 / progress: Training / epsilon: 0.8844539999966774 / score: 479.1850169748068\n",
      "step: 165977 / episode: 38 / progress: Training / epsilon: 0.884023999996665 / score: 216.90808688104153\n",
      "step: 170076 / episode: 39 / progress: Training / epsilon: 0.8799249999965472 / score: 1538.7973219901323\n",
      "step: 172944 / episode: 40 / progress: Training / epsilon: 0.8770569999964647 / score: 596.640370413661\n",
      "step: 177085 / episode: 41 / progress: Training / epsilon: 0.8729159999963456 / score: 1317.7332495748997\n",
      "step: 180089 / episode: 42 / progress: Training / epsilon: 0.8699119999962592 / score: 750.8427168875933\n",
      "step: 182212 / episode: 43 / progress: Training / epsilon: 0.8677889999961982 / score: 707.4423758685589\n",
      "step: 186566 / episode: 44 / progress: Training / epsilon: 0.863434999996073 / score: 853.1859776675701\n",
      "step: 190895 / episode: 45 / progress: Training / epsilon: 0.8591059999959485 / score: 1209.446269735694\n",
      "step: 195166 / episode: 46 / progress: Training / epsilon: 0.8548349999958257 / score: 1196.5035650730133\n",
      "step: 199240 / episode: 47 / progress: Training / epsilon: 0.8507609999957085 / score: 1592.3653647452593\n",
      "step: 203662 / episode: 48 / progress: Training / epsilon: 0.8463389999955814 / score: 940.2244176417589\n",
      "step: 204573 / episode: 49 / progress: Training / epsilon: 0.8454279999955552 / score: 141.66361139714718\n",
      "step: 209039 / episode: 50 / progress: Training / epsilon: 0.8409619999954268 / score: 817.5184905230999\n",
      "step: 209602 / episode: 51 / progress: Training / epsilon: 0.8403989999954106 / score: 205.19584839046001\n",
      "step: 213685 / episode: 52 / progress: Training / epsilon: 0.8363159999952932 / score: 1670.3615815341473\n",
      "step: 215844 / episode: 53 / progress: Training / epsilon: 0.8341569999952311 / score: 642.6911188960075\n",
      "step: 220356 / episode: 54 / progress: Training / epsilon: 0.8296449999951013 / score: 688.8621146082878\n",
      "step: 222193 / episode: 55 / progress: Training / epsilon: 0.8278079999950485 / score: 722.8879312872887\n",
      "step: 223331 / episode: 56 / progress: Training / epsilon: 0.8266699999950158 / score: 338.9022639989853\n",
      "step: 224014 / episode: 57 / progress: Training / epsilon: 0.8259869999949961 / score: 195.34755286574364\n",
      "step: 228155 / episode: 58 / progress: Training / epsilon: 0.8218459999948771 / score: 1653.008951947093\n",
      "step: 228561 / episode: 59 / progress: Training / epsilon: 0.8214399999948654 / score: 156.08840046823025\n",
      "step: 232995 / episode: 60 / progress: Training / epsilon: 0.8170059999947379 / score: 1127.1458286345005\n",
      "step: 237489 / episode: 61 / progress: Training / epsilon: 0.8125119999946087 / score: 987.6845201551914\n",
      "step: 241744 / episode: 62 / progress: Training / epsilon: 0.8082569999944863 / score: 1266.3455723822117\n",
      "step: 242776 / episode: 63 / progress: Training / epsilon: 0.8072249999944566 / score: 380.9047881513834\n",
      "step: 243404 / episode: 64 / progress: Training / epsilon: 0.8065969999944386 / score: 344.20080672204494\n",
      "step: 247485 / episode: 65 / progress: Training / epsilon: 0.8025159999943212 / score: 1547.6131812781096\n",
      "step: 251549 / episode: 66 / progress: Training / epsilon: 0.7984519999942044 / score: 1446.0245180875063\n",
      "step: 255678 / episode: 67 / progress: Training / epsilon: 0.7943229999940856 / score: 1519.5497855693102\n",
      "step: 259285 / episode: 68 / progress: Training / epsilon: 0.7907159999939819 / score: 935.2474960386753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 263473 / episode: 69 / progress: Training / epsilon: 0.7865279999938615 / score: 1410.3379526883364\n",
      "step: 267418 / episode: 70 / progress: Training / epsilon: 0.782582999993748 / score: 1746.6719843447208\n",
      "step: 268185 / episode: 71 / progress: Training / epsilon: 0.781815999993726 / score: 302.1650262326002\n",
      "step: 272645 / episode: 72 / progress: Training / epsilon: 0.7773559999935977 / score: 904.4200411438942\n",
      "step: 274287 / episode: 73 / progress: Training / epsilon: 0.7757139999935505 / score: 728.755104586482\n",
      "step: 278864 / episode: 74 / progress: Training / epsilon: 0.7711369999934189 / score: 766.6310531944036\n",
      "step: 279634 / episode: 75 / progress: Training / epsilon: 0.7703669999933968 / score: 215.79902900755405\n",
      "step: 283048 / episode: 76 / progress: Training / epsilon: 0.7669529999932986 / score: 967.6565200686455\n",
      "step: 287402 / episode: 77 / progress: Training / epsilon: 0.7625989999931734 / score: 978.034416615963\n",
      "step: 287725 / episode: 78 / progress: Training / epsilon: 0.7622759999931641 / score: 206.7420173883438\n",
      "step: 292122 / episode: 79 / progress: Training / epsilon: 0.7578789999930376 / score: 1065.7690194994211\n",
      "step: 295782 / episode: 80 / progress: Training / epsilon: 0.7542189999929324 / score: 1338.209957703948\n",
      "step: 296957 / episode: 81 / progress: Training / epsilon: 0.7530439999928986 / score: 480.11731043457985\n",
      "step: 297531 / episode: 82 / progress: Training / epsilon: 0.7524699999928821 / score: 178.2319246828556\n",
      "step: 301628 / episode: 83 / progress: Training / epsilon: 0.7483729999927643 / score: 1460.0838757157326\n",
      "step: 303933 / episode: 84 / progress: Training / epsilon: 0.746067999992698 / score: 784.8577300608158\n",
      "step: 307730 / episode: 85 / progress: Training / epsilon: 0.7422709999925888 / score: 1982.1720137149096\n",
      "step: 311947 / episode: 86 / progress: Training / epsilon: 0.7380539999924676 / score: 1292.3259588479996\n",
      "step: 316258 / episode: 87 / progress: Training / epsilon: 0.7337429999923436 / score: 1050.2323245555162\n",
      "step: 317024 / episode: 88 / progress: Training / epsilon: 0.7329769999923216 / score: 291.6602282524109\n",
      "step: 320848 / episode: 89 / progress: Training / epsilon: 0.7291529999922116 / score: 1952.6133692115545\n",
      "step: 321185 / episode: 90 / progress: Training / epsilon: 0.7288159999922019 / score: 169.43119499087334\n",
      "step: 323715 / episode: 91 / progress: Training / epsilon: 0.7262859999921292 / score: 469.10467602312565\n",
      "step: 327991 / episode: 92 / progress: Training / epsilon: 0.7220099999920062 / score: 1312.839479252696\n",
      "step: 332595 / episode: 93 / progress: Training / epsilon: 0.7174059999918738 / score: 738.7274695336819\n",
      "step: 335902 / episode: 94 / progress: Training / epsilon: 0.7140989999917787 / score: 1194.28421472013\n",
      "step: 339869 / episode: 95 / progress: Training / epsilon: 0.7101319999916647 / score: 1698.5498752593994\n",
      "step: 343929 / episode: 96 / progress: Training / epsilon: 0.7060719999915479 / score: 1575.2488823235035\n",
      "step: 347812 / episode: 97 / progress: Training / epsilon: 0.7021889999914362 / score: 2012.4770285636187\n",
      "step: 348363 / episode: 98 / progress: Training / epsilon: 0.7016379999914204 / score: 373.6987757384777\n",
      "step: 352408 / episode: 99 / progress: Training / epsilon: 0.6975929999913041 / score: 1563.372499793768\n",
      "step: 356786 / episode: 100 / progress: Training / epsilon: 0.6932149999911782 / score: 1026.334633141756\n",
      "step: 359149 / episode: 101 / progress: Training / epsilon: 0.6908519999911102 / score: 835.3988969922066\n",
      "step: 360484 / episode: 102 / progress: Training / epsilon: 0.6895169999910719 / score: 573.6214872896671\n",
      "step: 363683 / episode: 103 / progress: Training / epsilon: 0.6863179999909799 / score: 714.5179791599512\n",
      "step: 367810 / episode: 104 / progress: Training / epsilon: 0.6821909999908612 / score: 1575.9541637003422\n",
      "step: 369895 / episode: 105 / progress: Training / epsilon: 0.6801059999908012 / score: 336.90797182917595\n",
      "step: 371982 / episode: 106 / progress: Training / epsilon: 0.6780189999907412 / score: 1066.162299260497\n",
      "step: 375973 / episode: 107 / progress: Training / epsilon: 0.6740279999906265 / score: 1618.779822781682\n",
      "step: 376313 / episode: 108 / progress: Training / epsilon: 0.6736879999906167 / score: 254.50918313860893\n",
      "step: 380588 / episode: 109 / progress: Training / epsilon: 0.6694129999904938 / score: 1301.842006161809\n",
      "step: 383208 / episode: 110 / progress: Training / epsilon: 0.6667929999904184 / score: 1095.1224426031113\n",
      "step: 384067 / episode: 111 / progress: Training / epsilon: 0.6659339999903937 / score: 348.02730448544025\n",
      "step: 388753 / episode: 112 / progress: Training / epsilon: 0.661247999990259 / score: 674.3963638693094\n",
      "step: 392652 / episode: 113 / progress: Training / epsilon: 0.6573489999901468 / score: 1869.6018726080656\n",
      "step: 396589 / episode: 114 / progress: Training / epsilon: 0.6534119999900336 / score: 1716.8395496308804\n",
      "step: 400690 / episode: 115 / progress: Training / epsilon: 0.6493109999899157 / score: 1572.1904926300049\n",
      "step: 400992 / episode: 116 / progress: Training / epsilon: 0.649008999989907 / score: 187.19998951256275\n",
      "step: 405295 / episode: 117 / progress: Training / epsilon: 0.6447059999897833 / score: 1124.0480999052525\n",
      "step: 409247 / episode: 118 / progress: Training / epsilon: 0.6407539999896696 / score: 1696.1316962689161\n",
      "step: 413058 / episode: 119 / progress: Training / epsilon: 0.63694299998956 / score: 2023.9616393595934\n",
      "step: 417634 / episode: 120 / progress: Training / epsilon: 0.6323669999894285 / score: 851.7314663231373\n",
      "step: 419267 / episode: 121 / progress: Training / epsilon: 0.6307339999893815 / score: 794.9041778147221\n",
      "step: 423374 / episode: 122 / progress: Training / epsilon: 0.6266269999892634 / score: 1429.8017988801003\n",
      "step: 427081 / episode: 123 / progress: Training / epsilon: 0.6229199999891568 / score: 2171.1771132051945\n",
      "step: 431315 / episode: 124 / progress: Training / epsilon: 0.6186859999890351 / score: 1404.7468332648277\n",
      "step: 435354 / episode: 125 / progress: Training / epsilon: 0.6146469999889189 / score: 1662.2350403815508\n",
      "step: 439260 / episode: 126 / progress: Training / epsilon: 0.6107409999888066 / score: 1887.1423095017672\n",
      "step: 441733 / episode: 127 / progress: Training / epsilon: 0.6082679999887355 / score: 1452.43971593678\n",
      "step: 445558 / episode: 128 / progress: Training / epsilon: 0.6044429999886255 / score: 1942.0639016330242\n",
      "step: 449702 / episode: 129 / progress: Training / epsilon: 0.6002989999885063 / score: 1464.8890151828527\n",
      "step: 450407 / episode: 130 / progress: Training / epsilon: 0.5995939999884861 / score: 399.61911514401436\n",
      "step: 450771 / episode: 131 / progress: Training / epsilon: 0.5992299999884756 / score: 216.8614498525858\n",
      "step: 451491 / episode: 132 / progress: Training / epsilon: 0.5985099999884549 / score: 359.2998055368662\n",
      "step: 452073 / episode: 133 / progress: Training / epsilon: 0.5979279999884382 / score: 432.7456532418728\n",
      "step: 455139 / episode: 134 / progress: Training / epsilon: 0.59486199998835 / score: 916.281312122941\n",
      "step: 459389 / episode: 135 / progress: Training / epsilon: 0.5906119999882278 / score: 1337.7230585366488\n",
      "step: 460033 / episode: 136 / progress: Training / epsilon: 0.5899679999882093 / score: 403.3564605116844\n",
      "step: 464225 / episode: 137 / progress: Training / epsilon: 0.5857759999880887 / score: 1507.2790599912405\n",
      "step: 468343 / episode: 138 / progress: Training / epsilon: 0.5816579999879703 / score: 1582.894287288189\n",
      "step: 472237 / episode: 139 / progress: Training / epsilon: 0.5777639999878583 / score: 1967.0531617999077\n",
      "step: 474675 / episode: 140 / progress: Training / epsilon: 0.5753259999877882 / score: 1072.4233120679855\n",
      "step: 477381 / episode: 141 / progress: Training / epsilon: 0.5726199999877104 / score: 1069.7947404384613\n",
      "step: 481171 / episode: 142 / progress: Training / epsilon: 0.5688299999876014 / score: 1959.6347467303276\n",
      "step: 484953 / episode: 143 / progress: Training / epsilon: 0.5650479999874927 / score: 2169.008039265871\n",
      "step: 485567 / episode: 144 / progress: Training / epsilon: 0.564433999987475 / score: 247.8819952905178\n",
      "step: 489503 / episode: 145 / progress: Training / epsilon: 0.5604979999873618 / score: 1911.0996524989605\n",
      "step: 493838 / episode: 146 / progress: Training / epsilon: 0.5561629999872372 / score: 1181.8452599048615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 496303 / episode: 147 / progress: Training / epsilon: 0.5536979999871663 / score: 1046.8435120284557\n",
      "step: 498231 / episode: 148 / progress: Training / epsilon: 0.5517699999871108 / score: 580.312436491251\n",
      "step: 502025 / episode: 149 / progress: Training / epsilon: 0.5479759999870017 / score: 2086.7180997878313\n",
      "step: 505914 / episode: 150 / progress: Training / epsilon: 0.5440869999868899 / score: 1979.537411302328\n",
      "step: 510027 / episode: 151 / progress: Training / epsilon: 0.5399739999867716 / score: 1547.7134614735842\n",
      "step: 511999 / episode: 152 / progress: Training / epsilon: 0.5380019999867149 / score: 1165.4174547195435\n",
      "step: 513395 / episode: 153 / progress: Training / epsilon: 0.5366059999866748 / score: 603.7891589552164\n",
      "step: 517247 / episode: 154 / progress: Training / epsilon: 0.532753999986564 / score: 2008.683905556798\n",
      "step: 518822 / episode: 155 / progress: Training / epsilon: 0.5311789999865187 / score: 701.0136257261038\n",
      "step: 521820 / episode: 156 / progress: Training / epsilon: 0.5281809999864325 / score: 1507.257831349969\n",
      "step: 522040 / episode: 157 / progress: Training / epsilon: 0.5279609999864262 / score: 110.19636480510235\n",
      "step: 524935 / episode: 158 / progress: Training / epsilon: 0.525065999986343 / score: 977.1697192937136\n",
      "step: 528599 / episode: 159 / progress: Training / epsilon: 0.5214019999862376 / score: 2266.5929213166237\n",
      "step: 531543 / episode: 160 / progress: Training / epsilon: 0.5184579999861529 / score: 1518.4192150086164\n",
      "step: 533229 / episode: 161 / progress: Training / epsilon: 0.5167719999861045 / score: 788.5468706786633\n",
      "step: 536058 / episode: 162 / progress: Training / epsilon: 0.5139429999860231 / score: 928.1216385066509\n",
      "step: 539959 / episode: 163 / progress: Training / epsilon: 0.5100419999859109 / score: 1940.087745204568\n",
      "step: 543715 / episode: 164 / progress: Training / epsilon: 0.5062859999858029 / score: 2086.95865739882\n",
      "step: 544054 / episode: 165 / progress: Training / epsilon: 0.5059469999857932 / score: 223.96794739365578\n",
      "step: 544657 / episode: 166 / progress: Training / epsilon: 0.5053439999857758 / score: 423.5787052065134\n",
      "step: 548543 / episode: 167 / progress: Training / epsilon: 0.5014579999856641 / score: 1862.9944256097078\n",
      "step: 550574 / episode: 168 / progress: Training / epsilon: 0.49942699998563755 / score: 1153.5788196474314\n",
      "step: 554502 / episode: 169 / progress: Training / epsilon: 0.49549899998574265 / score: 1924.848553031683\n",
      "step: 557043 / episode: 170 / progress: Training / epsilon: 0.49295799998581064 / score: 1276.4133769273758\n",
      "step: 561218 / episode: 171 / progress: Training / epsilon: 0.48878299998592234 / score: 1534.036619976163\n",
      "step: 563793 / episode: 172 / progress: Training / epsilon: 0.48620799998599123 / score: 1461.4126303344965\n",
      "step: 564717 / episode: 173 / progress: Training / epsilon: 0.48528399998601596 / score: 384.9120769351721\n",
      "step: 568623 / episode: 174 / progress: Training / epsilon: 0.48137799998612046 / score: 2005.328951627016\n",
      "step: 569717 / episode: 175 / progress: Training / epsilon: 0.48028399998614973 / score: 640.8394664525986\n",
      "step: 570828 / episode: 176 / progress: Training / epsilon: 0.47917299998617946 / score: 604.833948418498\n",
      "step: 574993 / episode: 177 / progress: Training / epsilon: 0.4750079999862909 / score: 1602.455335944891\n",
      "step: 576504 / episode: 178 / progress: Training / epsilon: 0.4734969999863313 / score: 1078.30172508955\n",
      "step: 580436 / episode: 179 / progress: Training / epsilon: 0.4695649999864365 / score: 2011.8935867697\n",
      "step: 584191 / episode: 180 / progress: Training / epsilon: 0.465809999986537 / score: 2153.171721071005\n",
      "step: 584996 / episode: 181 / progress: Training / epsilon: 0.46500499998655853 / score: 521.2717762589455\n",
      "step: 588731 / episode: 182 / progress: Training / epsilon: 0.46126999998665846 / score: 2310.9339472800493\n",
      "step: 593155 / episode: 183 / progress: Training / epsilon: 0.45684599998677683 / score: 1247.879777237773\n",
      "step: 594432 / episode: 184 / progress: Training / epsilon: 0.455568999986811 / score: 895.0778677761555\n",
      "step: 598389 / episode: 185 / progress: Training / epsilon: 0.45161199998691687 / score: 1950.8755620867014\n",
      "step: 602311 / episode: 186 / progress: Training / epsilon: 0.4476899999870218 / score: 1935.7610671967268\n",
      "step: 606131 / episode: 187 / progress: Training / epsilon: 0.443869999987124 / score: 1849.2527706474066\n",
      "step: 610115 / episode: 188 / progress: Training / epsilon: 0.4398859999872306 / score: 1871.4180619716644\n",
      "step: 613712 / episode: 189 / progress: Training / epsilon: 0.43628899998732684 / score: 2427.146758362651\n",
      "step: 617633 / episode: 190 / progress: Training / epsilon: 0.43236799998743175 / score: 2039.9287275373936\n",
      "step: 621389 / episode: 191 / progress: Training / epsilon: 0.42861199998753224 / score: 2179.9653479754925\n",
      "step: 621746 / episode: 192 / progress: Training / epsilon: 0.4282549999875418 / score: 274.178985863924\n",
      "step: 623475 / episode: 193 / progress: Training / epsilon: 0.42652599998758806 / score: 1250.555468916893\n",
      "step: 627086 / episode: 194 / progress: Training / epsilon: 0.42291499998768467 / score: 1744.323210760951\n",
      "step: 630890 / episode: 195 / progress: Training / epsilon: 0.41911099998778645 / score: 2094.5014364868402\n",
      "step: 632298 / episode: 196 / progress: Training / epsilon: 0.4177029999878241 / score: 879.3701269626617\n",
      "step: 636516 / episode: 197 / progress: Training / epsilon: 0.413484999987937 / score: 1554.6839049309492\n",
      "step: 640048 / episode: 198 / progress: Training / epsilon: 0.4099529999880315 / score: 2471.5801774412394\n",
      "step: 643059 / episode: 199 / progress: Training / epsilon: 0.40694199998811204 / score: 1660.2629590779543\n",
      "step: 646374 / episode: 200 / progress: Training / epsilon: 0.40362699998820073 / score: 1359.6005225032568\n",
      "step: 649382 / episode: 201 / progress: Training / epsilon: 0.4006189999882812 / score: 1828.8180179446936\n",
      "step: 650962 / episode: 202 / progress: Training / epsilon: 0.3990389999883235 / score: 325.0633899718523\n",
      "step: 654672 / episode: 203 / progress: Training / epsilon: 0.39532899998842275 / score: 2333.634765163064\n",
      "step: 659073 / episode: 204 / progress: Training / epsilon: 0.3909279999885405 / score: 1305.5252548605204\n",
      "step: 662948 / episode: 205 / progress: Training / epsilon: 0.3870529999886442 / score: 2123.166087165475\n",
      "step: 667583 / episode: 206 / progress: Training / epsilon: 0.3824179999887682 / score: 946.1725894212723\n",
      "step: 671280 / episode: 207 / progress: Training / epsilon: 0.3787209999888671 / score: 2363.0127523988485\n",
      "step: 674279 / episode: 208 / progress: Training / epsilon: 0.37572199998894734 / score: 765.4505196362734\n",
      "step: 676296 / episode: 209 / progress: Training / epsilon: 0.3737049999890013 / score: 1126.976888164878\n",
      "step: 679989 / episode: 210 / progress: Training / epsilon: 0.3700119999891001 / score: 2386.898912295699\n",
      "step: 683766 / episode: 211 / progress: Training / epsilon: 0.36623499998920117 / score: 2086.6721463650465\n",
      "step: 687861 / episode: 212 / progress: Training / epsilon: 0.36213999998931073 / score: 1806.4056604653597\n",
      "step: 689617 / episode: 213 / progress: Training / epsilon: 0.3603839999893577 / score: 1214.4309369325638\n",
      "step: 693622 / episode: 214 / progress: Training / epsilon: 0.3563789999894649 / score: 1706.5558527857065\n",
      "step: 695521 / episode: 215 / progress: Training / epsilon: 0.3544799999895157 / score: 1087.4122281819582\n",
      "step: 699092 / episode: 216 / progress: Training / epsilon: 0.3509089999896112 / score: 2480.4969241321087\n",
      "step: 703314 / episode: 217 / progress: Training / epsilon: 0.3466869999897242 / score: 1506.6788720190525\n",
      "step: 707635 / episode: 218 / progress: Training / epsilon: 0.3423659999898398 / score: 1543.0751826316118\n",
      "step: 712141 / episode: 219 / progress: Training / epsilon: 0.33785999998996036 / score: 1239.0180922299623\n",
      "step: 715837 / episode: 220 / progress: Training / epsilon: 0.33416399999005925 / score: 2355.1185591369867\n",
      "step: 719529 / episode: 221 / progress: Training / epsilon: 0.330471999990158 / score: 1770.4660841822624\n",
      "step: 721755 / episode: 222 / progress: Training / epsilon: 0.3282459999902176 / score: 795.8605600446463\n",
      "step: 725517 / episode: 223 / progress: Training / epsilon: 0.32448399999031824 / score: 2367.5174382030964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 728988 / episode: 224 / progress: Training / epsilon: 0.3210129999904111 / score: 2714.3598853498697\n",
      "step: 732628 / episode: 225 / progress: Training / epsilon: 0.3173729999905085 / score: 2440.4368229210377\n",
      "step: 736584 / episode: 226 / progress: Training / epsilon: 0.31341699999061434 / score: 2128.4409288167953\n",
      "step: 738157 / episode: 227 / progress: Training / epsilon: 0.31184399999065643 / score: 917.7157562971115\n",
      "step: 741935 / episode: 228 / progress: Training / epsilon: 0.3080659999907575 / score: 2276.4101743102074\n",
      "step: 744569 / episode: 229 / progress: Training / epsilon: 0.305431999990828 / score: 1191.4638617634773\n",
      "step: 746057 / episode: 230 / progress: Training / epsilon: 0.3039439999908678 / score: 745.2543102055788\n",
      "step: 749948 / episode: 231 / progress: Training / epsilon: 0.3000529999909719 / score: 2094.570143312216\n",
      "step: 751483 / episode: 232 / progress: Training / epsilon: 0.29851799999101297 / score: 878.9694866091013\n",
      "step: 755719 / episode: 233 / progress: Training / epsilon: 0.2942819999911263 / score: 1713.5603371560574\n",
      "step: 759897 / episode: 234 / progress: Training / epsilon: 0.2901039999912381 / score: 1738.9831096827984\n",
      "step: 763820 / episode: 235 / progress: Training / epsilon: 0.28618099999134305 / score: 2103.1526528149843\n",
      "step: 766371 / episode: 236 / progress: Training / epsilon: 0.2836299999914113 / score: 1426.8934226185083\n",
      "step: 767669 / episode: 237 / progress: Training / epsilon: 0.28233199999144604 / score: 898.8762510120869\n",
      "step: 767984 / episode: 238 / progress: Training / epsilon: 0.28201699999145446 / score: 263.47499945759773\n",
      "step: 772010 / episode: 239 / progress: Training / epsilon: 0.2779909999915622 / score: 2062.288868173957\n",
      "step: 774660 / episode: 240 / progress: Training / epsilon: 0.2753409999916331 / score: 1764.1423800587654\n",
      "step: 775183 / episode: 241 / progress: Training / epsilon: 0.2748179999916471 / score: 392.70421256124973\n",
      "step: 776919 / episode: 242 / progress: Training / epsilon: 0.2730819999916935 / score: 1412.6128423064947\n",
      "step: 779647 / episode: 243 / progress: Training / epsilon: 0.2703539999917665 / score: 1358.5106932222843\n",
      "step: 783914 / episode: 244 / progress: Training / epsilon: 0.2660869999918807 / score: 1644.8765955418348\n",
      "step: 787693 / episode: 245 / progress: Training / epsilon: 0.2623079999919818 / score: 2375.4675952643156\n",
      "step: 791277 / episode: 246 / progress: Training / epsilon: 0.2587239999920777 / score: 2591.5171042233706\n",
      "step: 794748 / episode: 247 / progress: Training / epsilon: 0.25525299999217055 / score: 2766.1373601406813\n",
      "step: 796643 / episode: 248 / progress: Training / epsilon: 0.25335799999222125 / score: 1325.2653664499521\n",
      "step: 797207 / episode: 249 / progress: Training / epsilon: 0.25279399999223634 / score: 509.88740861415863\n",
      "step: 797580 / episode: 250 / progress: Training / epsilon: 0.2524209999922463 / score: 314.55529391765594\n",
      "step: 801279 / episode: 251 / progress: Training / epsilon: 0.2487219999923098 / score: 2443.57950527966\n",
      "step: 805784 / episode: 252 / progress: Training / epsilon: 0.24421699999230528 / score: 1543.3827551603317\n",
      "step: 806629 / episode: 253 / progress: Training / epsilon: 0.24337199999230444 / score: 505.09272588789463\n",
      "step: 808965 / episode: 254 / progress: Training / epsilon: 0.2410359999923021 / score: 1866.64965210855\n",
      "step: 811310 / episode: 255 / progress: Training / epsilon: 0.23869099999229976 / score: 1670.2699375599623\n",
      "step: 813631 / episode: 256 / progress: Training / epsilon: 0.23636999999229744 / score: 1075.4189378917217\n",
      "step: 817652 / episode: 257 / progress: Training / epsilon: 0.23234899999229341 / score: 2048.2597945928574\n",
      "step: 818655 / episode: 258 / progress: Training / epsilon: 0.2313459999922924 / score: 872.6592476963997\n",
      "step: 822896 / episode: 259 / progress: Training / epsilon: 0.22710499999228817 / score: 1833.5071040540934\n",
      "step: 823675 / episode: 260 / progress: Training / epsilon: 0.2263259999922874 / score: 600.4688454419374\n",
      "step: 827781 / episode: 261 / progress: Training / epsilon: 0.22221999999228328 / score: 2057.5641579180956\n",
      "step: 832012 / episode: 262 / progress: Training / epsilon: 0.21798899999227905 / score: 1839.6743893623352\n",
      "step: 832789 / episode: 263 / progress: Training / epsilon: 0.21721199999227828 / score: 667.1844623684883\n",
      "step: 836785 / episode: 264 / progress: Training / epsilon: 0.21321599999227428 / score: 2074.060722693801\n",
      "step: 840827 / episode: 265 / progress: Training / epsilon: 0.20917399999227024 / score: 2130.1370269060135\n",
      "step: 841224 / episode: 266 / progress: Training / epsilon: 0.20877699999226984 / score: 316.14946652948856\n",
      "step: 843721 / episode: 267 / progress: Training / epsilon: 0.20627999999226734 / score: 1910.0155508220196\n",
      "step: 844133 / episode: 268 / progress: Training / epsilon: 0.20586799999226693 / score: 366.9500008523464\n",
      "step: 847816 / episode: 269 / progress: Training / epsilon: 0.20218499999226325 / score: 2523.415377885103\n",
      "step: 848160 / episode: 270 / progress: Training / epsilon: 0.2018409999922629 / score: 274.1144106835127\n",
      "step: 849714 / episode: 271 / progress: Training / epsilon: 0.20028699999226135 / score: 1124.702419936657\n",
      "step: 853435 / episode: 272 / progress: Training / epsilon: 0.19656599999225763 / score: 2506.848879635334\n",
      "step: 856935 / episode: 273 / progress: Training / epsilon: 0.19306599999225413 / score: 2756.8763493150473\n",
      "step: 860813 / episode: 274 / progress: Training / epsilon: 0.18918799999225025 / score: 2301.7242208868265\n",
      "step: 865110 / episode: 275 / progress: Training / epsilon: 0.18489099999224595 / score: 1767.3832429349422\n",
      "step: 868695 / episode: 276 / progress: Training / epsilon: 0.18130599999224237 / score: 2637.825187191367\n",
      "step: 872757 / episode: 277 / progress: Training / epsilon: 0.1772439999922383 / score: 2167.72944162786\n",
      "step: 876648 / episode: 278 / progress: Training / epsilon: 0.1733529999922344 / score: 2298.236434161663\n",
      "step: 877930 / episode: 279 / progress: Training / epsilon: 0.17207099999223313 / score: 632.4392324835062\n",
      "step: 881648 / episode: 280 / progress: Training / epsilon: 0.1683529999922294 / score: 2505.6971565932035\n",
      "step: 885847 / episode: 281 / progress: Training / epsilon: 0.1641539999922252 / score: 1866.9683815389872\n",
      "step: 889735 / episode: 282 / progress: Training / epsilon: 0.16026599999222133 / score: 2314.5020432174206\n",
      "step: 890374 / episode: 283 / progress: Training / epsilon: 0.1596269999922207 / score: 502.18443259596825\n",
      "step: 894479 / episode: 284 / progress: Training / epsilon: 0.15552199999221658 / score: 2032.6792464256287\n",
      "step: 898296 / episode: 285 / progress: Training / epsilon: 0.15170499999221276 / score: 2419.2450469732285\n",
      "step: 901714 / episode: 286 / progress: Training / epsilon: 0.14828699999220935 / score: 2362.8113391399384\n",
      "step: 903713 / episode: 287 / progress: Training / epsilon: 0.14628799999220735 / score: 1360.5662336945534\n",
      "step: 906522 / episode: 288 / progress: Training / epsilon: 0.14347899999220454 / score: 1534.8406210243702\n",
      "step: 906833 / episode: 289 / progress: Training / epsilon: 0.14316799999220423 / score: 268.7043317258358\n",
      "step: 910404 / episode: 290 / progress: Training / epsilon: 0.13959699999220065 / score: 2695.5620158314705\n",
      "step: 913773 / episode: 291 / progress: Training / epsilon: 0.13622799999219729 / score: 2058.5476294457912\n",
      "step: 917424 / episode: 292 / progress: Training / epsilon: 0.13257699999219363 / score: 2623.475716292858\n",
      "step: 921321 / episode: 293 / progress: Training / epsilon: 0.12867999999218974 / score: 2301.275829449296\n",
      "step: 923516 / episode: 294 / progress: Training / epsilon: 0.12648499999218754 / score: 1812.4329822212458\n",
      "step: 927410 / episode: 295 / progress: Training / epsilon: 0.12259099999218365 / score: 2362.4376799464226\n",
      "step: 931205 / episode: 296 / progress: Training / epsilon: 0.11879599999217985 / score: 2478.7288056761026\n",
      "step: 932088 / episode: 297 / progress: Training / epsilon: 0.11791299999217897 / score: 806.599072188139\n",
      "step: 936009 / episode: 298 / progress: Training / epsilon: 0.11399199999217505 / score: 2261.717298746109\n",
      "step: 936834 / episode: 299 / progress: Training / epsilon: 0.11316699999217422 / score: 639.8356112241745\n",
      "step: 940375 / episode: 300 / progress: Training / epsilon: 0.10962599999217068 / score: 2776.317076563835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 943944 / episode: 301 / progress: Training / epsilon: 0.10605699999216711 / score: 2729.2090810239315\n",
      "step: 945341 / episode: 302 / progress: Training / epsilon: 0.10465999999216571 / score: 1243.4559264183044\n",
      "step: 949454 / episode: 303 / progress: Training / epsilon: 0.1005469999921616 / score: 2151.6312170624733\n",
      "step: 952891 / episode: 304 / progress: Training / epsilon: 0.09999999999216105 / score: 2888.0221408605576\n",
      "step: 956564 / episode: 305 / progress: Training / epsilon: 0.09999999999216105 / score: 2532.2987395823\n",
      "step: 958593 / episode: 306 / progress: Training / epsilon: 0.09999999999216105 / score: 1676.8678030222654\n",
      "step: 962660 / episode: 307 / progress: Training / epsilon: 0.09999999999216105 / score: 2179.5906291157007\n",
      "step: 963843 / episode: 308 / progress: Training / epsilon: 0.09999999999216105 / score: 801.9914474487305\n",
      "step: 967275 / episode: 309 / progress: Training / epsilon: 0.09999999999216105 / score: 2938.538444623351\n",
      "step: 971242 / episode: 310 / progress: Training / epsilon: 0.09999999999216105 / score: 2220.0083379745483\n",
      "step: 973573 / episode: 311 / progress: Training / epsilon: 0.09999999999216105 / score: 1855.5710393637419\n",
      "step: 977270 / episode: 312 / progress: Training / epsilon: 0.09999999999216105 / score: 2636.946336582303\n",
      "step: 977441 / episode: 313 / progress: Training / epsilon: 0.09999999999216105 / score: 154.42500072717667\n",
      "step: 977793 / episode: 314 / progress: Training / epsilon: 0.09999999999216105 / score: 322.8249990195036\n",
      "step: 981154 / episode: 315 / progress: Training / epsilon: 0.09999999999216105 / score: 2793.851617321372\n",
      "step: 984781 / episode: 316 / progress: Training / epsilon: 0.09999999999216105 / score: 2646.4441291838884\n",
      "step: 988312 / episode: 317 / progress: Training / epsilon: 0.09999999999216105 / score: 2844.1915116906166\n",
      "step: 991901 / episode: 318 / progress: Training / epsilon: 0.09999999999216105 / score: 2763.1210888028145\n",
      "step: 993531 / episode: 319 / progress: Training / epsilon: 0.09999999999216105 / score: 1053.713344797492\n",
      "step: 997289 / episode: 320 / progress: Training / epsilon: 0.09999999999216105 / score: 2429.2274041175842\n",
      "step: 1000907 / episode: 321 / progress: Training / epsilon: 0.09999999999216105 / score: 2717.719309017062\n",
      "step: 1002044 / episode: 322 / progress: Training / epsilon: 0.09999999999216105 / score: 989.6501912325621\n",
      "step: 1005158 / episode: 323 / progress: Training / epsilon: 0.09999999999216105 / score: 2111.211305126548\n",
      "step: 1008858 / episode: 324 / progress: Training / epsilon: 0.09999999999216105 / score: 2639.3021145164967\n",
      "step: 1010407 / episode: 325 / progress: Training / epsilon: 0.09999999999216105 / score: 1361.2063808590174\n",
      "step: 1013766 / episode: 326 / progress: Training / epsilon: 0.09999999999216105 / score: 3045.784835755825\n",
      "step: 1017928 / episode: 327 / progress: Training / epsilon: 0.09999999999216105 / score: 2125.235916852951\n",
      "step: 1021637 / episode: 328 / progress: Training / epsilon: 0.09999999999216105 / score: 2531.112736478448\n",
      "step: 1022929 / episode: 329 / progress: Training / epsilon: 0.09999999999216105 / score: 859.6502077579498\n",
      "step: 1026430 / episode: 330 / progress: Training / epsilon: 0.09999999999216105 / score: 2827.044767200947\n",
      "step: 1027951 / episode: 331 / progress: Training / epsilon: 0.09999999999216105 / score: 1350.0624066144228\n",
      "step: 1031833 / episode: 332 / progress: Training / epsilon: 0.09999999999216105 / score: 2257.5024086385965\n",
      "step: 1035737 / episode: 333 / progress: Training / epsilon: 0.09999999999216105 / score: 2413.42788285017\n",
      "step: 1036585 / episode: 334 / progress: Training / epsilon: 0.09999999999216105 / score: 486.4953725486994\n",
      "step: 1040558 / episode: 335 / progress: Training / epsilon: 0.09999999999216105 / score: 2272.254437416792\n",
      "step: 1044898 / episode: 336 / progress: Training / epsilon: 0.09999999999216105 / score: 1781.5737317949533\n",
      "step: 1048501 / episode: 337 / progress: Training / epsilon: 0.09999999999216105 / score: 2748.2939308583736\n",
      "Model saved in file: ../saved_networks/2018-09-13_17_13_QR-DQN_both/model.ckpt\n",
      "step: 1052031 / episode: 338 / progress: Testing / epsilon: 0 / score: 2858.7921621501446\n",
      "step: 1055816 / episode: 339 / progress: Testing / epsilon: 0 / score: 2643.979349255562\n",
      "step: 1059289 / episode: 340 / progress: Testing / epsilon: 0 / score: 2973.1801028996706\n",
      "step: 1063129 / episode: 341 / progress: Testing / epsilon: 0 / score: 2561.3980135321617\n",
      "step: 1067113 / episode: 342 / progress: Testing / epsilon: 0 / score: 2382.989118605852\n",
      "step: 1071032 / episode: 343 / progress: Testing / epsilon: 0 / score: 2472.652319073677\n",
      "step: 1071283 / episode: 344 / progress: Testing / epsilon: 0 / score: 236.78323781490326\n",
      "step: 1072571 / episode: 345 / progress: Testing / epsilon: 0 / score: 1040.838760972023\n",
      "step: 1076346 / episode: 346 / progress: Testing / epsilon: 0 / score: 2650.3786842674017\n",
      "step: 1076635 / episode: 347 / progress: Testing / epsilon: 0 / score: 272.7750000357628\n",
      "step: 1080472 / episode: 348 / progress: Testing / epsilon: 0 / score: 2594.5212408155203\n",
      "step: 1083943 / episode: 349 / progress: Testing / epsilon: 0 / score: 3053.457933232188\n",
      "step: 1088051 / episode: 350 / progress: Testing / epsilon: 0 / score: 2322.8255521655083\n",
      "step: 1092199 / episode: 351 / progress: Testing / epsilon: 0 / score: 811.3089711070061\n",
      "step: 1095980 / episode: 352 / progress: Testing / epsilon: 0 / score: 2605.2692476809025\n",
      "step: 1097960 / episode: 353 / progress: Testing / epsilon: 0 / score: 1886.362711057067\n",
      "step: 1101785 / episode: 354 / progress: Testing / epsilon: 0 / score: 2579.900925576687\n",
      "step: 1105527 / episode: 355 / progress: Testing / epsilon: 0 / score: 2738.076904281974\n",
      "step: 1108802 / episode: 356 / progress: Testing / epsilon: 0 / score: 3235.857870683074\n",
      "step: 1109447 / episode: 357 / progress: Testing / epsilon: 0 / score: 453.2828311175108\n",
      "step: 1113042 / episode: 358 / progress: Testing / epsilon: 0 / score: 2787.295521259308\n",
      "step: 1117374 / episode: 359 / progress: Testing / epsilon: 0 / score: 2069.783465370536\n",
      "step: 1121043 / episode: 360 / progress: Testing / epsilon: 0 / score: 2771.9368306696415\n",
      "step: 1123853 / episode: 361 / progress: Testing / epsilon: 0 / score: 2531.9572142511606\n",
      "step: 1127667 / episode: 362 / progress: Testing / epsilon: 0 / score: 2552.0593908280134\n",
      "step: 1131250 / episode: 363 / progress: Testing / epsilon: 0 / score: 2901.906519636512\n",
      "step: 1134051 / episode: 364 / progress: Testing / epsilon: 0 / score: 1948.5631475299597\n",
      "step: 1135517 / episode: 365 / progress: Testing / epsilon: 0 / score: 881.0051496773958\n",
      "step: 1138129 / episode: 366 / progress: Testing / epsilon: 0 / score: 2210.0675944536924\n",
      "step: 1142174 / episode: 367 / progress: Testing / epsilon: 0 / score: 2370.0964977890253\n",
      "step: 1145829 / episode: 368 / progress: Testing / epsilon: 0 / score: 2711.1757154911757\n",
      "step: 1149764 / episode: 369 / progress: Testing / epsilon: 0 / score: 2535.4459925442934\n",
      "Finished!!\n"
     ]
    }
   ],
   "source": [
    "check_plot = 0\n",
    "\n",
    "# Training & Testing\n",
    "while True:\n",
    "   \n",
    "    # Get Progress, train mode\n",
    "    progress, train_mode, Epsilon  = get_progress(step, Epsilon)\n",
    "    \n",
    "    # Select Actions \n",
    "    action, Q_value = select_action(progress, sess, observation_stack, state_stack, Epsilon)\n",
    "    action_in = [np.argmax(action)]\n",
    "    \n",
    "    # Get information for plotting\n",
    "    vehicle_speed  = 100 * env_info.vector_observations[0][-8]\n",
    "    num_overtake   = env_info.vector_observations[0][-7]\n",
    "    num_lanechange = env_info.vector_observations[0][-6]\n",
    "    \n",
    "    # Get information for update\n",
    "    env_info = env.step(action_in)[default_brain]\n",
    "\n",
    "    next_observation_stack, observation_set, next_state_stack, state_set = resize_input(env_info, observation_set, state_set) \n",
    "    reward = env_info.rewards[0]\n",
    "    terminal = env_info.local_done[0]\n",
    "    \n",
    "    if progress == 'Training':\n",
    "        # Train!! \n",
    "        train(Replay_memory, sess, step)\n",
    "\n",
    "        # Save the variables to disk.\n",
    "        if step == Num_start_training + Num_training:\n",
    "            save_path = saver.save(sess, '../saved_networks/' + date_time + '_' + algorithm + '_both' + \"/model.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # If progress is finished -> close! \n",
    "    if progress == 'Finished':\n",
    "        print('Finished!!')\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "    Replay_memory = Experience_Replay(progress, \n",
    "                                      Replay_memory, \n",
    "                                      observation_stack, \n",
    "                                      state_stack,\n",
    "                                      action, \n",
    "                                      reward, \n",
    "                                      next_observation_stack,\n",
    "                                      next_state_stack,\n",
    "                                      terminal)\n",
    "    \n",
    "    # Update information\n",
    "    step += 1\n",
    "    score += reward\n",
    "    step_per_episode += 1\n",
    "    \n",
    "    observation_stack = next_observation_stack\n",
    "    state_stack = next_state_stack\n",
    "    \n",
    "    # Update tensorboard\n",
    "    if progress != 'Observing':\n",
    "        speed_list.append(vehicle_speed)\n",
    "        \n",
    "        if episode % Num_plot_episode == 0 and check_plot == 1 and episode != 0:\n",
    "            avg_speed      = sum(speed_list) / len(speed_list)\n",
    "            avg_overtake   = sum(overtake_list) / len(overtake_list)\n",
    "            avg_lanechange = sum(lanechange_list) / len(lanechange_list)\n",
    "            \n",
    "            tensorboard_info = [avg_speed, avg_overtake, avg_lanechange]\n",
    "            for i in range(len(tensorboard_info)):\n",
    "                sess.run(update_ops[i], feed_dict = {summary_placeholders[i]: float(tensorboard_info[i])})\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "            score_board = 0\n",
    "            \n",
    "            speed_list = []\n",
    "            overtake_list = []\n",
    "            lanechange_list = []\n",
    "\n",
    "            check_plot = 0\n",
    "            \n",
    "    # If terminal is True\n",
    "    if terminal == True:\n",
    "        # Print informations\n",
    "        print('step: ' + str(step) + ' / '  + 'episode: ' + str(episode) + ' / ' + 'progress: ' + progress  + ' / ' + 'epsilon: ' + str(Epsilon)  +' / ' + 'score: ' + str(score))\n",
    "\n",
    "        check_plot = 1\n",
    "\n",
    "        if progress != 'Observing':\n",
    "            episode += 1\n",
    "            \n",
    "            score_board += score\n",
    "            overtake_list.append(num_overtake)\n",
    "            lanechange_list.append(num_lanechange)\n",
    "        \n",
    "            \n",
    "        score = 0\n",
    "        step_per_episode = 0\n",
    "\n",
    "        # Initialize game state\n",
    "        env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "        observation_stack, observation_set, state_stack, state_set = input_initialization(env_info)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
